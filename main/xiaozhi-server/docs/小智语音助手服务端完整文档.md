# 小智语音助手服务端完整文档

## 目录
1. [项目概述](#项目概述)
2. [项目架构](#项目架构)
3. [启动流程](#启动流程)
4. [模块设计](#模块设计)
5. [WebSocket协议](#websocket协议)
6. [HTTP API接口](#http-api接口)
7. [前后端交互](#前后端交互)
8. [部署指南](#部署指南)

---

## 项目概述

小智语音助手是一个企业级的AI语音交互系统，包含服务端和多个客户端实现。项目采用WebSocket + HTTP双协议架构，支持实时语音对话、文本聊天、视觉分析等功能。

**当前状态**: 项目正在进行生产级改造，从玩具状态升级为企业级应用。详细改造计划见[生产级改造计划.md](./生产级改造计划.md)。

### 技术栈
- **后端**: Python 3.8+, AsyncIO, WebSocket, aiohttp
- **前端**: Flutter (Android/iOS), Vue.js (Web管理端)  
- **AI能力**: ASR、TTS、LLM、VAD、VLLM等多模态AI模块
- **数据库**: SQLite (本地), MySQL (智控台), Redis (缓存)
- **架构**: 插件化、模块化、微服务化
- **监控**: Prometheus + Grafana, ELK Stack
- **部署**: Docker, Kubernetes, CI/CD

### 项目结构
```
xiaozhi-esp32-server/
├── main/xiaozhi-server/           # 核心服务器
│   ├── modules/                   # AI模块实现
│   ├── providers/                 # Provider接口实现
│   ├── handlers/                  # 连接处理器
│   ├── tools/                     # 工具系统
│   ├── config/                    # 配置管理
│   └── docs/                      # 项目文档
├── main/manager-api/              # 智控台后端API
├── main/manager-web/              # Web管理界面
└── docs/                          # 全局文档
```

---

## 项目架构

### 整体架构
```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   客户端设备     │    │   服务端核心     │    │   智控台系统     │
├─────────────────┤    ├─────────────────┤    ├─────────────────┤
│ ESP32固件       │◄──►│ WebSocket服务    │◄──►│ Manager API     │
│ Android App     │    │ HTTP API服务     │    │ Manager Web     │
│ Flutter App     │    │ AI Provider层    │    │ 设备管理        │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                              │
                       ┌─────────────┐
                       │ AI服务层     │
                       ├─────────────┤
                       │ ASR语音识别  │
                       │ TTS语音合成  │
                       │ LLM大模型    │
                       │ VAD语音检测  │
                       │ VLLM视觉     │
                       │ Memory记忆   │
                       │ Intent意图   │
                       └─────────────┘
```

### 核心服务架构

#### 1. WebSocket服务 (端口8000)
- **连接管理**: 支持多客户端并发连接
- **消息路由**: 根据消息类型分发处理
- **实时通信**: 语音数据流、文本消息双向传输
- **认证机制**: Bearer Token + 设备ID验证

#### 2. HTTP服务 (端口8003)
- **OTA接口**: 设备固件更新检查
- **视觉分析**: 图像理解和说明生成
- **CORS支持**: 跨域请求处理

#### 3. AI Provider层
采用插件化架构，每个AI能力都有统一的基类定义和多种具体实现:

```python
# 示例：ASR模块架构
ASRProviderBase (抽象基类)
├── BaiduASR (百度语音识别)
├── AliyunASR (阿里云ASR)
├── TencentASR (腾讯云ASR)
├── DoubaoASR (豆包ASR)
├── FunASR (本地模型)
└── SherpaASR (开源模型)
```

---

## 启动流程

### 1. 应用入口 (app.py)
```python
async def main():
    # 1. 环境检查
    check_ffmpeg_installed()
    
    # 2. 加载配置
    config = load_config()
    
    # 3. 生成认证密钥
    auth_key = generate_auth_key(config)
    
    # 4. 启动服务
    ws_server = WebSocketServer(config)      # WebSocket服务
    http_server = SimpleHttpServer(config)   # HTTP服务
    
    # 5. 并发运行
    await asyncio.gather(
        ws_server.start(),
        http_server.start(),
        monitor_stdin()
    )
```

### 2. WebSocket服务启动
```python
class WebSocketServer:
    async def start(self):
        # 1. 初始化AI模块
        modules = initialize_modules(config)
        
        # 2. 启动WebSocket监听
        async with websockets.serve(
            self._handle_connection, 
            host="0.0.0.0", 
            port=8000
        ):
            # 3. 等待连接
            await asyncio.Future()
```

### 3. 连接处理流程
```python
async def handle_connection(self, websocket):
    # 1. 获取请求头
    headers = dict(websocket.request.headers)
    
    # 2. 身份认证
    await auth.authenticate(headers)
    
    # 3. 创建连接处理器
    handler = ConnectionHandler(config, modules...)
    
    # 4. 初始化组件
    handler._initialize_components()
    
    # 5. 消息循环
    async for message in websocket:
        await handler._route_message(message)
```

---

## 模块设计

### 1. ASR (语音识别) 模块

#### 基类定义
```python
class ASRProviderBase(ABC):
    @abstractmethod
    async def speech_to_text(self, opus_data: List[bytes], 
                           session_id: str, audio_format="opus") -> Tuple[str, str]:
        """音频转文字核心方法"""
        pass
    
    async def receive_audio(self, conn, audio, audio_have_voice):
        """接收音频数据处理"""
        pass
```

#### 支持的ASR服务商
| 服务商 | 类型 | 特点 |
|--------|------|------|
| 百度ASR | 云端 | 支持多种方言，准确率高 |
| 阿里云ASR | 云端 | 支持实时流式，低延迟 |
| 腾讯ASR | 云端 | 支持热词、替换词 |
| 豆包ASR | 云端 | 字节跳动，中文优化 |
| FunASR | 本地 | 开源本地模型，隐私性好 |
| Sherpa-ONNX | 本地 | 轻量级ONNX模型 |

### 2. TTS (语音合成) 模块

#### 基类定义
```python
class TTSProviderBase(ABC):
    @abstractmethod
    async def text_to_speech(self, text: str, audio_format="opus") -> bytes:
        """文字转语音核心方法"""
        pass
    
    def split_sentences(self, text: str) -> List[str]:
        """智能分句处理"""
        pass
```

#### 文本处理策略
- **首句快速响应**: 使用扩展标点符号集快速切分首句
- **智能分段**: 根据标点符号进行动态分段
- **缓冲机制**: 维护文本缓冲区，优化播放连续性

#### 支持的TTS服务商
| 服务商 | 类型 | 特点 |
|--------|------|------|
| EdgeTTS | 免费 | 微软Edge，音质优秀 |
| 阿里云TTS | 付费 | 多种音色，支持SSML |
| 豆包TTS | 付费 | 自然度高，中文优化 |
| 火山双流TTS | 付费 | 实时流式合成 |
| GPT-SoVITS | 本地 | 语音克隆，个性化 |
| FishSpeech | 本地 | 开源本地TTS |

### 3. LLM (大语言模型) 模块

#### 基类定义
```python
class LLMProviderBase(ABC):
    @abstractmethod
    def response(self, session_id: str, dialogue: List[Dict]) -> Iterator[str]:
        """流式响应生成器"""
        pass
    
    def response_with_functions(self, session_id: str, dialogue: List[Dict], 
                              functions: List[Dict]) -> Iterator[Tuple[str, List]]:
        """支持函数调用的响应"""
        pass
```

#### 支持的LLM服务商
| 服务商 | 类型 | 特点 |
|--------|------|------|
| ChatGLM | 免费 | 智谱AI，glm-4-flash免费 |
| 豆包LLM | 付费 | 字节跳动，中文优化 |
| 阿里百炼 | 付费 | 通义千问，支持应用模式 |
| DeepSeek | 付费 | 性价比高，推理能力强 |
| OpenAI | 付费 | GPT系列，能力最强 |
| Ollama | 本地 | 本地部署，隐私保护 |
| Gemini | 付费 | Google，多模态支持 |

### 4. VAD (语音活动检测) 模块

#### 实现原理
```python
class SileroVAD:
    def __init__(self, threshold=0.5, threshold_low=0.3):
        self.threshold = threshold        # 高阈值
        self.threshold_low = threshold_low # 低阈值
        
    def is_vad(self, conn, data) -> bool:
        # 1. 音频预处理
        audio_int16 = self.preprocess_audio(data)
        
        # 2. VAD检测
        voice_prob = self.model(audio_int16)
        
        # 3. 双阈值判断
        return self.apply_threshold_logic(voice_prob)
```

### 5. Memory (记忆) 模块

#### 本地短期记忆实现
```python
class MemLocalShort:
    def __init__(self):
        self.evaluation_weights = {
            'timeliness': 0.40,      # 时效性权重
            'emotion': 0.35,         # 情感强度权重  
            'association': 0.25      # 关联密度权重
        }
    
    async def save_memory(self, msgs: List[Dict]):
        """三维度评估保存记忆"""
        pass
    
    async def query_memory(self, query: str) -> str:
        """检索相关记忆"""
        pass
```

### 6. Intent (意图识别) 模块

#### 支持的意图识别模式
1. **无意图识别** (`nointent`): 简单实现，始终继续对话
2. **函数调用模式** (`function_call`): 基于LLM的Function Calling
3. **LLM意图模式** (`intent_llm`): 专用LLM进行意图理解

### 7. Tools (工具调用) 模块

#### 统一工具架构
```python
class ToolType(Enum):
    SERVER_PLUGIN = "server_plugin"    # 服务端插件
    SERVER_MCP = "server_mcp"          # 服务端MCP
    DEVICE_IOT = "device_iot"          # 设备端IoT
    DEVICE_MCP = "device_mcp"          # 设备端MCP  
    MCP_ENDPOINT = "mcp_endpoint"      # MCP接入点
```

#### 内置工具函数
- **get_weather**: 天气查询 (和风天气API)
- **get_news**: 新闻获取 (中新网RSS)
- **play_music**: 音乐播放 (本地音乐库)
- **change_role**: 角色切换
- **home_assistant**: 智能家居控制

---

## WebSocket协议

### 1. 连接建立

#### 连接URL
```
ws://服务器IP:8000/xiaozhi/v1/
```

#### 认证方式
```javascript
// 请求头方式
headers: {
    "device-id": "设备MAC地址",
    "client-id": "客户端ID", 
    "Authorization": "Bearer token"
}

// 或查询参数方式
ws://服务器IP:8000/xiaozhi/v1/?device-id=xx&client-id=xx
```

### 2. 消息协议

#### Hello握手
```json
// 客户端发送
{
    "type": "hello",
    "version": 1,
    "transport": "websocket",
    "audio_params": {
        "format": "opus",
        "sample_rate": 16000,
        "channels": 1,
        "frame_duration": 60
    }
}

// 服务端响应
{
    "type": "hello",
    "session_id": "唯一会话ID",
    "version": 1
}
```

#### 文本聊天
```json
// 客户端发送文本
{
    "type": "listen",
    "state": "detect", 
    "text": "用户输入的文本",
    "source": "text"
}

// 服务端回复
{
    "type": "tts",
    "state": "sentence_start",
    "text": "助手的回复文本",
    "session_id": "会话ID"
}
```

#### 语音对话控制
```json
// 开始说话模式
{
    "type": "speak",
    "state": "start",
    "mode": "auto"
}

// 开始监听
{
    "type": "listen", 
    "state": "start",
    "mode": "auto",
    "session_id": "会话ID"
}

// 停止监听
{
    "type": "listen",
    "state": "stop", 
    "session_id": "会话ID"
}

// 中止对话
{
    "type": "abort",
    "session_id": "会话ID"
}
```

#### 语音数据传输
- **格式**: Opus编码的二进制数据
- **参数**: 16kHz采样率, 单声道, 60ms帧长
- **传输**: WebSocket二进制帧

#### 语音识别结果
```json
{
    "type": "stt",
    "text": "识别的语音文本",
    "session_id": "会话ID"
}
```

### 3. 状态管理

#### 会话状态
- `session_id`: 每个连接分配唯一会话ID
- `client_is_speaking`: 客户端说话状态
- `client_listen_mode`: 监听模式 (auto/manual)

#### 错误处理
```json
{
    "type": "error",
    "code": "错误码",
    "message": "错误描述",
    "session_id": "会话ID"
}
```

---

## HTTP API接口

### 1. OTA接口

#### 1.1 状态检查
```http
GET /xiaozhi/ota/
```

**响应**: 
```
OTA接口运行正常，向设备发送的websocket地址是：ws://192.168.1.100:8000/xiaozhi/v1/
```

#### 1.2 OTA信息获取
```http
POST /xiaozhi/ota/
Content-Type: application/json

{
    "application": {
        "version": "1.0.0"
    }
}
```

**请求头**:
- `device-id`: 设备ID (必需)

**响应**:
```json
{
    "server_time": {
        "timestamp": 1699123456789,
        "timezone_offset": 480
    },
    "firmware": {
        "version": "1.0.0", 
        "url": ""
    },
    "websocket": {
        "url": "ws://192.168.1.100:8000/xiaozhi/v1/"
    }
}
```

### 2. 视觉分析接口

#### 2.1 状态检查
```http
GET /mcp/vision/explain
```

#### 2.2 图像分析
```http
POST /mcp/vision/explain
Content-Type: multipart/form-data
Authorization: Bearer <token>
Device-Id: <设备ID>
Client-Id: <客户端ID>
```

**请求参数**:
- `question`: 用户问题 (文本字段)
- `image`: 图片文件 (最大5MB)

**支持格式**: JPEG, PNG, GIF, BMP, TIFF, WEBP

**响应**:
```json
{
    "success": true,
    "action": "RESPONSE",
    "response": "这是对图片的分析结果..."
}
```

**错误响应**:
```json
{
    "success": false,
    "message": "错误描述"
}
```

### 3. 跨域支持

所有HTTP接口都支持CORS:
```http
Access-Control-Allow-Origin: *
Access-Control-Allow-Headers: client-id, content-type, device-id
Access-Control-Allow-Credentials: true
```

---

## 前后端交互

### 1. Android客户端交互

#### 核心类结构
```dart
// 主要服务类
XiaozhiService               // 业务逻辑层
XiaozhiWebSocketManager      // WebSocket连接管理
AudioUtil                    // 音频处理工具

// 数据模型
XiaozhiServiceEvent         // 服务事件
XiaozhiEvent               // WebSocket事件
```

#### 交互流程

##### 文本聊天流程
```dart
// 1. 连接服务
await service.connect();

// 2. 发送文本消息
String response = await service.sendTextMessage("你好");

// 3. 监听响应
service.addListener((event) {
    if (event.type == XiaozhiServiceEventType.textMessage) {
        // 处理文本回复
        handleTextResponse(event.data);
    }
});
```

##### 语音通话流程
```dart
// 1. 切换到语音模式
await service.switchToVoiceCallMode();

// 2. 连接语音通话
await service.connectVoiceCall();

// 3. 开始录音说话
await service.startListeningCall();

// 4. 监听音频和文本事件
service.addListener((event) {
    switch (event.type) {
        case XiaozhiServiceEventType.audioData:
            // 播放音频
            break;
        case XiaozhiServiceEventType.userMessage:
            // 显示用户语音识别结果
            break;
        case XiaozhiServiceEventType.textMessage:
            // 显示助手回复
            break;
    }
});

// 5. 停止录音
await service.stopListeningCall();
```

### 2. Web管理端交互

#### 技术栈
- **前端**: Vue.js 2.x + Element UI
- **后端**: Spring Boot + MyBatis Plus
- **数据库**: MySQL

#### 主要功能模块
1. **用户管理**: 用户注册、登录、权限控制
2. **设备管理**: 设备绑定、配置、状态监控
3. **模型配置**: AI模型参数配置和切换
4. **OTA管理**: 固件版本管理和推送
5. **数据字典**: 系统配置项管理

### 3. 数据流转

```
┌─────────────┐    WebSocket     ┌─────────────┐    HTTP API    ┌─────────────┐
│   客户端     │ ◄─────────────► │  服务端核心  │ ◄─────────────► │  智控台API   │
│  (Flutter)  │   语音+文本       │ (Python)    │    配置+数据      │ (Spring)    │
└─────────────┘                 └─────────────┘                └─────────────┘
      │                               │                               │
      │ 用户交互                       │ AI处理                         │ 管理配置
      ▼                               ▼                               ▼
┌─────────────┐                 ┌─────────────┐                ┌─────────────┐
│   UI界面     │                 │  AI Provider │                │   数据库     │
│  语音播放    │                 │  模块层      │                │  (MySQL)    │
│  文本显示    │                 │  ASR/TTS/LLM │                │  配置存储    │
└─────────────┘                 └─────────────┘                └─────────────┘
```

---

## 部署指南

### 1. 环境要求

#### 系统要求
- **操作系统**: Linux/Windows/macOS
- **Python版本**: 3.8+
- **内存**: 最低2GB，推荐4GB+
- **存储**: 最低10GB，推荐50GB+

#### 依赖软件
```bash
# FFmpeg (音频处理)
sudo apt install ffmpeg

# Python依赖
pip install -r requirements.txt
```

### 2. 单机部署

#### 快速启动
```bash
# 1. 克隆项目
git clone https://github.com/xinnan-tech/xiaozhi-esp32-server.git

# 2. 进入目录  
cd xiaozhi-esp32-server/main/xiaozhi-server

# 3. 安装依赖
pip install -r requirements.txt

# 4. 修改配置
cp config.yaml data/.config.yaml
# 编辑 data/.config.yaml 配置AI服务密钥

# 5. 启动服务
python app.py
```

#### 配置说明
```yaml
# 核心配置项
server:
  ip: 0.0.0.0           # 监听地址
  port: 8000            # WebSocket端口
  http_port: 8003       # HTTP端口

# AI模块选择
selected_module:
  VAD: SileroVAD        # 语音检测
  ASR: FunASR           # 语音识别  
  LLM: ChatGLMLLM       # 大语言模型
  TTS: EdgeTTS          # 语音合成
  Memory: nomem         # 记忆模块
  Intent: function_call # 意图识别

# LLM配置示例
LLM:
  ChatGLMLLM:
    type: openai
    model_name: glm-4-flash
    url: https://open.bigmodel.cn/api/paas/v4/
    api_key: "your-api-key"
```

### 3. Docker部署

#### 服务端Docker化
```dockerfile
# Dockerfile示例
FROM python:3.8-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8000 8003

CMD ["python", "app.py"]
```

#### Docker Compose部署
```yaml
version: '3.8'
services:
  xiaozhi-server:
    build: .
    ports:
      - "8000:8000"
      - "8003:8003"
    volumes:
      - ./data:/app/data
      - ./config:/app/config
    environment:
      - LOG_LEVEL=INFO
```

### 4. 智控台部署

#### 完整系统部署
```bash
# 1. 数据库准备
mysql -u root -p < schema.sql

# 2. 后端API启动
cd main/manager-api
mvn spring-boot:run

# 3. 前端构建
cd main/manager-web  
npm install
npm run build

# 4. 服务端启动
cd main/xiaozhi-server
# 修改配置启用智控台模式
echo "read_config_from_api: true" >> data/.config.yaml
python app.py
```

### 5. 生产环境优化

#### 性能调优
1. **音频处理优化**: 使用GPU加速的ASR/TTS模型
2. **并发控制**: 调整线程池大小和连接数限制
3. **缓存策略**: 启用Redis缓存LLM响应和音频文件
4. **负载均衡**: 使用Nginx反向代理多个服务实例

#### 监控告警
1. **日志监控**: 使用ELK栈收集分析日志
2. **性能监控**: 集成Prometheus + Grafana
3. **健康检查**: 实现HTTP健康检查端点
4. **告警通知**: 配置服务异常通知机制

#### 安全加固
1. **HTTPS加密**: 配置SSL证书，强制HTTPS访问
2. **访问控制**: 限制IP白名单，启用防火墙
3. **密钥管理**: 使用环境变量或密钥管理服务
4. **数据备份**: 定期备份配置文件和数据库

---

## 总结

小智语音助手服务端是一个功能完整、架构清晰的AI语音交互系统。通过模块化的设计和插件化的架构，能够灵活支持多种AI服务提供商，满足不同场景的部署需求。

### 主要特色
1. **双协议支持**: WebSocket实时通信 + HTTP RESTful接口
2. **多模态AI**: 语音、文本、视觉多种交互方式
3. **插件化架构**: 支持AI服务提供商的灵活切换
4. **智控台集成**: 完整的设备管理和配置系统
5. **多客户端支持**: ESP32、Android、iOS等多平台

### 技术优势
1. **异步高并发**: 基于AsyncIO的高性能架构
2. **流式处理**: 支持语音和文本的流式处理
3. **容错机制**: 完善的错误处理和重试逻辑
4. **扩展性好**: 易于添加新的AI服务和功能模块

该文档提供了项目的完整技术说明，可作为开发、部署和维护的重要参考资料。